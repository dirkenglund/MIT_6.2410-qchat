{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbe4a6fb",
   "metadata": {},
   "source": [
    "# LAB: Quantum Key Distribution Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce85b07",
   "metadata": {},
   "source": [
    "Now that you know how to operate the quED, I want you to take your knowledge of QKD and generate a key via BB84. For this write-up, I want you to focus on building a model of how the BB84 will work and then comparing your experiment to that model. \n",
    "\n",
    "## Goal of this lab\n",
    "\n",
    "In this lab, you'll be generating a secret key via BB84 quantum key distribution (QKD). This will involve several steps:\n",
    "1. Model the secret key rate you expect to see\n",
    "1. Verify you have a single photon source based on your measurements from the HBT.\n",
    "1. Generate a raw key and compare it to your model\n",
    "1. Perform post processing to generate a final key\n",
    "1. Propose next steps to improve the experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcf9aec",
   "metadata": {},
   "source": [
    "## Model the secret key rate you expect to see\n",
    "**Note to Jane: figure out how to make the ket notations work in Latex**\n",
    "\n",
    "\n",
    "\n",
    "* How fast can Alice encode photons?\n",
    "* What's the loss between Alice's source and Bob's measurement? If Alice sends 1 photon, what's the probability Bob gets a click?\n",
    "    Jane will tell you the transmission through the polarization optics and an estimate of the APD efficiency\n",
    "* How much of the raw key gets lost through sifting, BER estimate, information reconciliation, and privacy amplification?\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91007155",
   "metadata": {},
   "source": [
    "## Verify mean number of photons\n",
    "\n",
    "### BB84's security is based on the no-cloning theorem\n",
    "The no-cloning theorem states that for a given quanta in a superposition of eigenstates, it's impossible to produce a perfect copy. See, eg [Wootters and Zurek 1982](\"https://www.nature.com/articles/299802a0\") or [Dieks 1982](\"https://www.sciencedirect.com/science/article/pii/0375960182900846?via%3Dihub\").\n",
    "\n",
    "Photon number splitting attack [Brassard, Lutkenhaus, Mor, Sanders 2000](\"https://doi.org/10.1103/PhysRevLett.85.1330\")\n",
    "\n",
    "As you recall from the reading, the HBT experiment can be used to verify that we have a heralded single-photon source. Use your results from the last lab to justify why the quED is an appropriate source of single photons.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0e3914",
   "metadata": {},
   "source": [
    "## Establish correct polarization\n",
    "\n",
    "Unless you want to rotate the half wave plate (HWP) and polarization optics manually for every single bit, you're going to want to make sure you can control polarization optics via a Python script. We've provided a basic script for you below, which you can edit as you see fit.\n",
    "\n",
    "Before you test the script, you need to make sure that your HWP and polarizers are lined up where you think they are, ie if you send $0^{\\circ}$ to the HWP, how do you know if it's actually at $0^{\\circ}$? For the quTools set up, you can set the angle and then manually rotate the polarization to get the optics where you want them. Ask one of the instruction staff to show you how to do that. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef0fae8",
   "metadata": {},
   "source": [
    "## Generate bits and bases\n",
    "1. Start with many photons per bit\n",
    "1. Generate all the bases at the beginning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d9b246fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary Libraries\n",
    "\n",
    "# Generate the basis for each bit from Alice and Bob\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "LENGTH = 150;\n",
    "\n",
    "# Are we using PBS and 2 detectors?\n",
    "PBS  = False\n",
    "\n",
    "# Assign bit values\n",
    "# How can I actually incorporate this usefully?\n",
    "bH = 0\n",
    "bV = 1\n",
    "bD = 0\n",
    "bA = 1\n",
    "\n",
    "# Initialize the random bases for Alice and Bob. Let 0 be HV and 1 be AD\n",
    "basis_Alice = np.zeros((LENGTH))\n",
    "basis_Bob = np.zeros((LENGTH))\n",
    "\n",
    "# Now initialize the bit values for Alice\n",
    "bits_Alice = np.zeros((LENGTH))\n",
    "bits_Bob = np.zeros((LENGTH)) \n",
    "\n",
    "# Now set the correct values for Alice and Bob's rotation\n",
    "angles_Alice = np.zeros((LENGTH))\n",
    "angles_Bob = np.zeros((LENGTH))\n",
    "for x in range (LENGTH):\n",
    "    basis_Alice[x] = random.randint(0,1)\n",
    "    basis_Bob[x] = random.randint(0,1)\n",
    "    bits_Alice[x] = random.randint(0,1)\n",
    "    bits_Bob[x] = random.randint(0,1)\n",
    "    angles_Alice[x] = 22.5*basis_Alice[x] - 45*bits_Alice[x]\n",
    "    if PBS:\n",
    "        angles_Bob[x] = 22.5*basis_Bob[x] # this will rotate Bob's HWP as needed. You'll measure from 2 detectors\n",
    "    else:\n",
    "        angles_Bob[x] = 45*basis_Bob[x] - 90*bits_Bob[x] # this will tells us how to rotate the linear polarizer\n",
    "\n",
    "# print('Alices Basis :',basis_Alice)\n",
    "# print('Alices Bits  :',bits_Alice)\n",
    "# print(\"Alices Angles: %s\" %(angles_Alice))\n",
    "# print('Bob basis: ', basis_Bob)\n",
    "# print('Bob bits:  ',bits_Bob)\n",
    "# print('Bob angles:',angles_Bob)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "07a1b77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place holder for actual data gathering\n",
    "TT = 1.0 # set a value for transmission through system, loss, etc.\n",
    "\n",
    "detH = []\n",
    "detV = []\n",
    "\n",
    "for x in range(LENGTH):\n",
    "    angle = angles_Alice[x]\n",
    "    if random.random() <= TT:\n",
    "        if PBS:\n",
    "            if angle == 0 or abs(angle) == 45:\n",
    "                if angles_Bob[x] == 0:\n",
    "                    detH.append(int(angle == 0))\n",
    "                    detV.append(int(angle == 45))\n",
    "            else: # Alice is in D or A basis\n",
    "                if angles_Bob[x] == 22.5: # Bob is also in D or A basis\n",
    "                    detH.append(int(angle < 0))\n",
    "                    detV.append(int(angle > 0))\n",
    "            Hval = random.randint(0,1)\n",
    "            detH.append(Hval)\n",
    "            Vval = 1 - Hval\n",
    "            detV.append(1 - Hval)\n",
    "        else:\n",
    "            if angle*2 == angles_Bob[x]:\n",
    "                detH.append(1)\n",
    "            else:\n",
    "                detH.append(0)\n",
    "            detV.append(-1)\n",
    "    else:\n",
    "        detH.append(-1)\n",
    "        detV.append(-1) \n",
    "# print(detH)\n",
    "# print(detV)\n",
    "# print(bits_Alice ==)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3431a5b2",
   "metadata": {},
   "source": [
    "## Sift the raw bits\n",
    "\n",
    "You need to check several things:\n",
    "   1. Did Bob get a click?\n",
    "   1. If yes, did he have the same basis as Alice?\n",
    "   \n",
    "Based on your pre-lab, how many bits did you expect to see in the key (after sifting and comparing bases)? Why do you think the experiment differs from that expectation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "365b436d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "Bob_all = []\n",
    "Al_all = []\n",
    "\n",
    "\n",
    "detH = np.array(detH)\n",
    "detV = np.array(detV)\n",
    "# find cases where Bob gets exactly 1 click\n",
    "mask = (detH == 1) ^ (detV == 1) \n",
    "# returns array indices where Bob gets exactly 1 click\n",
    "ix = np.array(np.where(mask))[0] \n",
    "# find raw key length\n",
    "rkl = ix.size \n",
    "\n",
    "# look for cases where Alice and Bob have the same basis\n",
    "if PBS:\n",
    "    print('Jane needs to write this code')\n",
    "else:\n",
    "    for x in range(rkl):\n",
    "        nn = ix[x]\n",
    "        AA = angles_Alice[nn]\n",
    "        AB = angles_Bob[nn]\n",
    "        if AA*2 == AB:\n",
    "            Al_all.append(bits_Alice[nn])\n",
    "            Bob_all.append(bits_Bob[nn])\n",
    "\n",
    "\n",
    "print(Al_all == Bob_all)\n",
    "# print(Bob_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76932abb",
   "metadata": {},
   "source": [
    "## Information Reconciliation/Error Correction\n",
    "\n",
    "Alice and Bob want to make sure that any errors in their key are corrected, but they don't want Eve to get too much information. The figure of merit for information reconiciliation/error correction is bit error rate (BER), the ratio of bits that are incorrect.\n",
    "\n",
    "A basic error correction scheme is provided below. It first estimates the raw BER by having Alice and Bob compare the first `length_reveal` bits over a classical channel. Eve gets all the information Alice and Bob share over the classical channel, so Alice and Bob throw away those bits as they are no longer secret.\n",
    "\n",
    "**Write-up question:** Where do the errors come from? How is that reflected in your model? Think about the limitations of the polarization optics and dark counts, as a place to start.\n",
    "\n",
    "Another form of error correction is available here: I found a description of Cascade Error Correction [here](https://cascade-python.readthedocs.io/en/latest/protocol.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb6d6c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09\n"
     ]
    }
   ],
   "source": [
    "# Estimate the q BER by revealing some of the bits.\n",
    "\n",
    "length_reveal = 100\n",
    "\n",
    "# errors = (bits_tx_sifted[0:length_reveal - 1] != bits_rx_sifted[0:length_reveal - 1]).astype(int)\n",
    "# errors_total = errors.sum()\n",
    "# BER = 1.0/length_reveal * errors.sum()\n",
    "\n",
    "Al_all = np.random.randint(low = 0, high = 2, size = (length_reveal+30,))\n",
    "\n",
    "# give Bob some errors for testing\n",
    "err_vec = np.random.choice(2,length_reveal+30,p=[0.9,0.1])\n",
    "Bob_all = Al_all ^ err_vec\n",
    "\n",
    "key_test = Al_all[0:length_reveal]\n",
    "Bob_test = Bob_all[0:length_reveal]\n",
    "BERest =  np.mean(key_test != Bob_test)\n",
    "print(BERest)\n",
    "\n",
    "# Discard those bits\n",
    "Al_all = Al_all[length_reveal:]\n",
    "Bob_all = Bob_all[length_reveal:]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16820445",
   "metadata": {},
   "source": [
    "Now that Alice and Bob have an estimate of the quantum BER, they can evaluate to what degree Eve is interfering in their key distribution and if error correction coding will help them. If the qBER is too high (for this particular scheme, the cutoff is when qBER $\\geq 0.14$), the error-correction code will actually make the BER worse. This scheme can correct 1 error in every block of 7 bits.\n",
    "\n",
    "The below section uses a very simple one way Hamming code following the example in the section \"Error Correction for Quantum Key Distribution\" in Loepp and Wootters [book available online with MIT Library sign in](https://www.cambridge.org/core/books/abs/protecting-information/quantum-cryptography-revisited/8A88AA6C8C88E8A07E535FACEDE3C310). This allows Alice and Bob to reveal a minimum amount of information to Eve while doing error correction; the privacy amplification step then removes the information they did reveal to Eve.\n",
    "\n",
    "The Hamming code works in the following way: Bob and Alice take their raw key (`a` for Alice and `b` for Bob) and break it into blocks of 7 bits. Each block is multiplied by a 3x7 Hamming matrix `H`. For Alice, this results in `Ha` and for Bob `Hb`. Then Alice sends `Ha` to Bob. Bob finds `Ha - Hb = He` where `e` is the error vector, ie the vector that indicates whether `a == b` for each element. From there, Bob finds `e` and can use that to locate and then correct his bits. For a more in-depth explanation, I highly recommend checking out the linked section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93a12ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working out the Hamming Error matrix once\n",
    "\n",
    "n = 7\n",
    "k = np.log2(n+1).astype(int)\n",
    "\n",
    "H = np.array([[1,1,1,0,1,0,0],\n",
    "              [1,1,0,1,0,1,0],\n",
    "              [0,1,1,1,0,0,1]])\n",
    "\n",
    "# Define the error correction functions we'll need\n",
    "\n",
    "def errCor(err_mat,H,a,b,n):\n",
    "    # Multiply Alice's bits a by H\n",
    "    at = np.matrix.transpose(a)\n",
    "    Hat = np.matmul(H,at)\n",
    "    Hat = np.remainder(Hat,2) # we're doing bitwise operation, so we need to eliminate the overflow\n",
    "\n",
    "    # Multiply Bob's bits b by H\n",
    "    bt = np.matrix.transpose(b)\n",
    "    Hbt = np.matmul(H,bt)\n",
    "    Hbt = np.remainder(Hbt,2)\n",
    "    \n",
    "    # Find Hb - Ha = s \n",
    "    s = Hat ^ Hbt\n",
    "    sT = np.matrix.transpose(s)\n",
    "    \n",
    "    # s = He where e is the error vector.\n",
    "    # If we know s, we can find which row of the error matrix it matches\n",
    "    # Based on that, we know where the error is\n",
    "    x = np.where((err_mat==sT).all(axis=1))[0][0].astype(int)\n",
    "    err_vec = np.zeros((1,n))\n",
    "\n",
    "    if x < n: \n",
    "     err_vec[0,x] = 1\n",
    "     \n",
    "    ev = err_vec.astype(int)\n",
    "    ev = np.reshape(ev,(1,n))\n",
    "\n",
    "    \n",
    "    # Bob now has a corrected vector\n",
    "    # bc = binSub(b,err_vec)\n",
    "    bc = b ^ ev\n",
    "    return bc\n",
    "\n",
    "def makeErrMat(n,k,H):\n",
    "    err_mat = np.zeros((n+1,k))\n",
    "\n",
    "    for ii in range(n):\n",
    "        err_vec = np.zeros((n,1))\n",
    "        err_vec[ii] = 1\n",
    "        HeT = np.matmul(H,err_vec)\n",
    "        HeTT = np.matrix.transpose(HeT)\n",
    "        # print('err loc',err_vec)\n",
    "        # print('HeT', HeT)\n",
    "        err_mat[ii] = HeTT    \n",
    "\n",
    "    err_mat = err_mat.astype(int)\n",
    "    return err_mat\n",
    "\n",
    "err_mat = makeErrMat(n,k,H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b447faf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# do error correction for each block\n",
    "\n",
    "# The following is an example script\n",
    "LL = 31\n",
    "\n",
    "Al_all = np.random.randint(low = 0, high = 2, size = (LL,))\n",
    "\n",
    "\n",
    "\n",
    "err_all = np.zeros((LL)).astype(int)\n",
    "err_all[3] = 1\n",
    "err_all[26] = 1\n",
    "err_all[18] = 1\n",
    "\n",
    "\n",
    "Bob_all = Al_all ^ err_all\n",
    "\n",
    "\n",
    "# We've skipped sifting for now\n",
    "sk = Bob_all.size\n",
    "\n",
    "cutoff =  sk % n # find key length modulo n\n",
    "\n",
    "# elimate the \"cut-off\" bits\n",
    "Bob = Bob_all[0:-cutoff]\n",
    "\n",
    "# reshape Alice and Bob's bits into a 2d matrix\n",
    "a = np.array([[1,0,0,0,1,1,1]])\n",
    "b = np.array([[1,0,0,0,1,1,0]])\n",
    "\n",
    "\n",
    "Bob = np.reshape(Bob,(-1,n))\n",
    "Al  = np.reshape(Al_all[0:-cutoff],(-1,n))\n",
    "Al[1,:] = a\n",
    "Bob[1,:] = b\n",
    "\n",
    "shape = np.shape(Al)\n",
    "Bob_corr = np.zeros((shape)).astype(int) #initialize matrix for Bob's error correction\n",
    "words = shape[0]\n",
    "\n",
    "for ii in range(words):\n",
    "    Al_word = Al[ii,:]\n",
    "    Bob_word = Bob[ii,:]\n",
    "    Bob_word_corr = errCor(err_mat, H, Al_word,Bob_word,n)\n",
    "    Bob_corr[ii,:] = Bob_word_corr\n",
    "    \n",
    "error = np.mean(Al != Bob_corr)\n",
    "print(error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594d176d",
   "metadata": {},
   "source": [
    "## Privacy Amplification\n",
    "\n",
    "In this set-up, Eve isn't interacting with the optical set-up, so the only information she has is what Alice and Bob share via the classical channel. \n",
    "So, following pg 184 from the above book, we simply get rid of the last 3 bits of each of the 7-word chunks, and Eve will have no information about Alice and Bob's shared key.\n",
    "\n",
    "There are a variety of ways to perform error correction and privacy amplification. The privacy ammplification needs to take into account how the error correction is done: if Alice and Bob reveal more information (which would allow the error correction to work for a worse qBER) they need to eliminate more bits to thwart Eve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba84b383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the giant matrix of error-correct keys, and just skip the last few columns (or rows)\n",
    "Bob_corr = Bob_corr[:,0:4]\n",
    "Al = Al[:,0:4]\n",
    "\n",
    "# Then reshape the key into one long string of bits\n",
    "Bob_key = np.reshape(Bob_corr,(1,-1))\n",
    "Al_key = np.reshape(Al,(1,-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174fe77b",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In your write-up, think about one way you could improved the SKR using commerically available components. How practical is the component for the speed-up? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
